# Pyspark Jobs & Unit Tests

## Project 
Create Pyspark jobs for actors_scd_backfill and user_devices_cumulation queries. Develop unit tests for each job.

<img src="https://github.com/Sarah269/bug-free-octo-sniffle/blob/main/Spark%20Jobs%20%26%20Unit%20Tests/Pyspark_job_flow.png" height=300>

## Reference
 - DataExpert.io Free Data Engineering Bootcamp
   
## Tools
- Python, Pyspark, Pytest, Chispa, SparkSQL

## [actors_scd_backfill_job.py](https://github.com/Sarah269/bug-free-octo-sniffle/blob/main/Spark%20Jobs%20%26%20Unit%20Tests/actors_scd_backfill_job.py)
<p>Populate actors_scd dimension table using a backfill query</p>

- SparkSQL backfill query to populate actors_scd
- do_actor_scd_transformation(spark,dataframe)
    - Create a view from the dataframe
    - Return results from backfill query
- main
    - Define Spark session
    - Execute backfill query
    - Insert backfill query results into actors_scd
 
## [user_devices_cumulation_job.py](https://github.com/Sarah269/bug-free-octo-sniffle/blob/main/Spark%20Jobs%20%26%20Unit%20Tests/user_activity_cumulation_job.py)
<p>Add current day's user activity to cumulated fact table stored in user_device_activity</p>

- do_user_activity_cumulation(spark, dataframe_cumulated, dataframe_devices, dataframe_event, ds_yesterday, ds_today)
  - SparkSQL cumulative query to add current activity to user_devices_cumulated
  - Convert dataframes to views
  - return query results

- main
  - Define Spark session
  - Execute cumulative query
  - insert cumulative query results into user_devices_cumulated

## Unit Test
- tests are using mock input and output data

### [test_actors_scd_backfill.py](https://github.com/Sarah269/bug-free-octo-sniffle/blob/main/Spark%20Jobs%20%26%20Unit%20Tests/test_actors_scd_backfill.py)
- Unit test for actors_scd_backfill to compare actual output dataframe to expected output dataframe
- create namedtuple for actors data, ActorYear
- create namedtuple for actors_scd data, ActorScd
- test_scd_generation
    - define input dataframe
    - define expected dataframe
    - Execute test
    - compare dataframe generated by test to expected dataframe 

### [test_actors_scd_cte_backfill.py](https://github.com/Sarah269/bug-free-octo-sniffle/blob/main/Spark%20Jobs%20%26%20Unit%20Tests/test_actors_scd_cte_backfill.py)
- Unit tests for CTEs in actors_scd_backfill query
- Pytest.fixtures
   - source_df
     - Define source data
   - with_prev
     - lag the quality_class and is_active columns in source data
   - with_chg_ind
     - set a flag to indicate change in value for quality_class or is_active
- test_with_previous
  - there is no data gte 1978 for the cte with_previous
- test_with_indicators
  - count the number of rows with a correct logic calculation for change indicator in cte with_indicators
- test_with_streaks
  -  compare actual number of streak_identifiers to expected streak_identifiers in cte with_streaks


### [test_user_devices_cumulation.py](https://github.com/Sarah269/bug-free-octo-sniffle/blob/main/Spark%20Jobs%20%26%20Unit%20Tests/test_user_activity_cumulation.py)
- Unit test for user_devices_cumulation cumulative query to compare actual output to expected output
- Create named tuples for device, event, and userDevicesCumulated
- Define Device data
- Define Event data
- Define User_devices_cumulated data
- Set data variables
- Define expected results
- test #1: compare row counts between actual and expected
- test #2: compare actual and expected dataframes

### Execute Unit Tests
- Execute unit test from Jupyter notebook with command: !pytest src (directory location of tests)

<img src="https://github.com/Sarah269/bug-free-octo-sniffle/blob/main/Spark%20Jobs%20%26%20Unit%20Tests/pytest_results.png" height=300>

